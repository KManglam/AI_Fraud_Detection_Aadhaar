{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aadhaar Fraud Detection - YOLOv8 Training\n",
        "\n",
        "This notebook trains a YOLOv8 model for detecting fraud indicators in Aadhaar documents:\n",
        "- Document tampering\n",
        "- Photo overlays\n",
        "- Tampered QR codes\n",
        "- Altered fonts\n",
        "- Subtle modifications\n",
        "\n",
        "## Prerequisites\n",
        "1. Upload your dataset to Google Drive\n",
        "2. Enable GPU runtime (Runtime → Change runtime type → GPU)"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q\n",
        "\n",
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configure Dataset Path\n",
        "\n",
        "Update the path below to match your Google Drive folder structure."
      ],
      "metadata": {
        "id": "config"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# UPDATE THIS PATH TO YOUR DATASET LOCATION\n",
        "# ============================================\n",
        "DATASET_PATH = \"/content/drive/MyDrive/AadhaarAuth_Dataset\"\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Verify dataset exists\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    print(\"Dataset found!\")\n",
        "    print(f\"Train images: {len(os.listdir(os.path.join(DATASET_PATH, 'train/images')))}\")\n",
        "    print(f\"Valid images: {len(os.listdir(os.path.join(DATASET_PATH, 'valid/images')))}\")\n",
        "    if os.path.exists(os.path.join(DATASET_PATH, 'test/images')):\n",
        "        print(f\"Test images: {len(os.listdir(os.path.join(DATASET_PATH, 'test/images')))}\")\n",
        "else:\n",
        "    print(f\"ERROR: Dataset not found at {DATASET_PATH}\")\n",
        "    print(\"Please update the DATASET_PATH variable above\")"
      ],
      "metadata": {
        "id": "verify_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data.yaml configuration\n",
        "data_yaml_content = f\"\"\"# Aadhaar Fraud Detection Dataset\n",
        "path: {DATASET_PATH}\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "\n",
        "# Number of classes (UPDATE THIS based on your dataset)\n",
        "nc: 5\n",
        "\n",
        "# Class names (UPDATE THIS based on your labels)\n",
        "names:\n",
        "  0: aadhaar_number\n",
        "  1: photo\n",
        "  2: qr_code\n",
        "  3: name_field\n",
        "  4: address_field\n",
        "\"\"\"\n",
        "\n",
        "# Save data.yaml\n",
        "with open('/content/data.yaml', 'w') as f:\n",
        "    f.write(data_yaml_content)\n",
        "\n",
        "print(\"Created data.yaml:\")\n",
        "print(data_yaml_content)"
      ],
      "metadata": {
        "id": "create_yaml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Explore Dataset"
      ],
      "metadata": {
        "id": "explore"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Get sample images\n",
        "train_images_path = os.path.join(DATASET_PATH, 'train/images')\n",
        "sample_images = random.sample(os.listdir(train_images_path), min(4, len(os.listdir(train_images_path))))\n",
        "\n",
        "# Display samples\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "for idx, img_name in enumerate(sample_images):\n",
        "    img_path = os.path.join(train_images_path, img_name)\n",
        "    img = Image.open(img_path)\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(img_name[:30] + '...' if len(img_name) > 30 else img_name)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize_samples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze label distribution\n",
        "from collections import Counter\n",
        "\n",
        "train_labels_path = os.path.join(DATASET_PATH, 'train/labels')\n",
        "class_counts = Counter()\n",
        "\n",
        "for label_file in os.listdir(train_labels_path):\n",
        "    with open(os.path.join(train_labels_path, label_file), 'r') as f:\n",
        "        for line in f:\n",
        "            class_id = int(line.strip().split()[0])\n",
        "            class_counts[class_id] += 1\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "for class_id, count in sorted(class_counts.items()):\n",
        "    print(f\"  Class {class_id}: {count} annotations\")\n",
        "\n",
        "# Plot distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_counts.keys(), class_counts.values())\n",
        "plt.xlabel('Class ID')\n",
        "plt.ylabel('Number of Annotations')\n",
        "plt.title('Class Distribution in Training Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "analyze_labels"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train YOLOv8 Model"
      ],
      "metadata": {
        "id": "train_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 model (use 'n' for nano, 's' for small, 'm' for medium, 'l' for large)\n",
        "# Start with 'n' or 's' for faster training, use 'm' or 'l' for better accuracy\n",
        "model = YOLO('yolov8m.pt')  # Medium model - good balance\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "EPOCHS = 100          # Number of training epochs\n",
        "BATCH_SIZE = 16       # Batch size (reduce if OOM error)\n",
        "IMG_SIZE = 640        # Image size\n",
        "PATIENCE = 20         # Early stopping patience\n",
        "\n",
        "# Output directory in Drive (to persist results)\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/AadhaarAuth_Models\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Training Configuration:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Image Size: {IMG_SIZE}\")\n",
        "print(f\"  Output: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "train_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "results = model.train(\n",
        "    data='/content/data.yaml',\n",
        "    epochs=EPOCHS,\n",
        "    batch=BATCH_SIZE,\n",
        "    imgsz=IMG_SIZE,\n",
        "    patience=PATIENCE,\n",
        "    project=OUTPUT_DIR,\n",
        "    name='aadhaar_fraud_detector',\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    box=7.5,\n",
        "    cls=0.5,\n",
        "    dfl=1.5,\n",
        "    augment=True,\n",
        "    cache=True,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate Model"
      ],
      "metadata": {
        "id": "evaluate_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "best_model_path = f\"{OUTPUT_DIR}/aadhaar_fraud_detector/weights/best.pt\"\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Validate on validation set\n",
        "val_results = best_model.val(data='/content/data.yaml')\n",
        "\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"  mAP50: {val_results.box.map50:.4f}\")\n",
        "print(f\"  mAP50-95: {val_results.box.map:.4f}\")\n",
        "print(f\"  Precision: {val_results.box.mp:.4f}\")\n",
        "print(f\"  Recall: {val_results.box.mr:.4f}\")"
      ],
      "metadata": {
        "id": "evaluate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on sample images\n",
        "test_images_path = os.path.join(DATASET_PATH, 'valid/images')\n",
        "test_samples = random.sample(os.listdir(test_images_path), min(6, len(os.listdir(test_images_path))))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "for idx, img_name in enumerate(test_samples):\n",
        "    img_path = os.path.join(test_images_path, img_name)\n",
        "    \n",
        "    # Run inference\n",
        "    results = best_model.predict(img_path, conf=0.25, verbose=False)\n",
        "    \n",
        "    # Plot result\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    result_img = results[0].plot()\n",
        "    ax.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
        "    ax.set_title(f\"{len(results[0].boxes)} detections\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/sample_predictions.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "test_inference"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Export Model"
      ],
      "metadata": {
        "id": "export_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to different formats\n",
        "print(\"Exporting model...\")\n",
        "\n",
        "# Export to ONNX (for cross-platform deployment)\n",
        "best_model.export(format='onnx', imgsz=640, simplify=True)\n",
        "\n",
        "# Export to TorchScript (for PyTorch deployment)\n",
        "best_model.export(format='torchscript', imgsz=640)\n",
        "\n",
        "print(\"\\nExported models:\")\n",
        "print(f\"  PyTorch: {best_model_path}\")\n",
        "print(f\"  ONNX: {best_model_path.replace('.pt', '.onnx')}\")\n",
        "print(f\"  TorchScript: {best_model_path.replace('.pt', '.torchscript')}\")"
      ],
      "metadata": {
        "id": "export"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy best model to easy download location\n",
        "import shutil\n",
        "\n",
        "final_model_path = f\"{OUTPUT_DIR}/aadhaar_fraud_detector_best.pt\"\n",
        "shutil.copy(best_model_path, final_model_path)\n",
        "\n",
        "print(f\"\\n✅ Training Complete!\")\n",
        "print(f\"\\nBest model saved to: {final_model_path}\")\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"1. Download the model from Google Drive\")\n",
        "print(f\"2. Place it in your project: backend/models/aadhaar_fraud_detector.pt\")\n",
        "print(f\"3. The backend will automatically use it for fraud detection\")"
      ],
      "metadata": {
        "id": "finalize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Quick Test (Optional)"
      ],
      "metadata": {
        "id": "quick_test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload and test your own image\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload an Aadhaar image to test:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    # Run inference\n",
        "    results = best_model.predict(filename, conf=0.25)\n",
        "    \n",
        "    # Display result\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    result_img = results[0].plot()\n",
        "    plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Detections: {len(results[0].boxes)}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    # Print detection details\n",
        "    print(\"\\nDetection Details:\")\n",
        "    for box in results[0].boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        cls_name = results[0].names[cls_id]\n",
        "        print(f\"  - {cls_name}: {conf:.2%} confidence\")"
      ],
      "metadata": {
        "id": "upload_test"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
